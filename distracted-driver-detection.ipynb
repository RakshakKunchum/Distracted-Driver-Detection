{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from glob import glob\nimport random\nimport time\nimport os\nimport tensorflow\nimport datetime\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom IPython.display import FileLink\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns \n\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_files\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import log_loss\n\n#model packages from keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.applications.vgg16 import VGG16","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:37:09.465841Z","iopub.execute_input":"2021-12-23T16:37:09.466221Z","iopub.status.idle":"2021-12-23T16:37:09.484445Z","shell.execute_reply.started":"2021-12-23T16:37:09.466165Z","shell.execute_reply":"2021-12-23T16:37:09.483615Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#input target class mapping csv file\nimages_list = pd.read_csv(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\nimages_list.head(10)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-12-23T16:37:09.486609Z","iopub.execute_input":"2021-12-23T16:37:09.486912Z","iopub.status.idle":"2021-12-23T16:37:09.527269Z","shell.execute_reply.started":"2021-12-23T16:37:09.486846Z","shell.execute_reply":"2021-12-23T16:37:09.526522Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"<h2>Exploratory Data Analysis and Training Data Preparation</h2>","metadata":{}},{"cell_type":"code","source":"#distinct no of drivers\ndriver = images_list.groupby('subject')\nunique_drivers = driver.groups.keys()\nprint(unique_drivers)\nlen(unique_drivers)","metadata":{"_cell_guid":"","_uuid":"","execution":{"iopub.status.busy":"2021-12-23T16:37:09.528522Z","iopub.execute_input":"2021-12-23T16:37:09.528953Z","iopub.status.idle":"2021-12-23T16:37:09.541170Z","shell.execute_reply.started":"2021-12-23T16:37:09.528905Z","shell.execute_reply":"2021-12-23T16:37:09.540164Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"no_of_classes = 10\n\n#loading the image\ndef get_cv2_image(path, img_rows, img_cols, color_type=3):\n    if color_type == 1:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3:\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n    # Reduce size\n    img = cv2.resize(img, (img_rows, img_cols)) \n    return img\n\n# Training\ndef load_train(img_rows, img_cols, color_type=3):\n    start_time = time.time()\n    train_images = [] \n    train_labels = []\n    # Loop over the training folder \n    for classed in tqdm(range(no_of_classes)):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('..', 'input', 'state-farm-distracted-driver-detection', 'imgs','train', 'c' + str(classed), '*.jpg'))\n        for file in files:\n            img = get_cv2_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classed)\n    print(\"Data Loaded in {} second\".format(time.time() - start_time))\n    return train_images, train_labels \n\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    X, labels = load_train(img_rows, img_cols, color_type)\n    y = np_utils.to_categorical(labels, 10)\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    return x_train, x_test, y_train, y_test\n\n# Validation\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    path = os.path.join('..', 'input', 'state-farm-distracted-driver-detection' , 'imgs', 'test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_cv2_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)\n    \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    \n    return test_data, test_ids","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:37:09.543115Z","iopub.execute_input":"2021-12-23T16:37:09.543520Z","iopub.status.idle":"2021-12-23T16:37:09.565202Z","shell.execute_reply.started":"2021-12-23T16:37:09.543350Z","shell.execute_reply":"2021-12-23T16:37:09.564544Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#setting default image dimensions and images colour for parsing images using cv2 library\nimg_rows = 64\nimg_cols = 64\ncolor_type = 1","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:37:09.567787Z","iopub.execute_input":"2021-12-23T16:37:09.568296Z","iopub.status.idle":"2021-12-23T16:37:09.573606Z","shell.execute_reply.started":"2021-12-23T16:37:09.568243Z","shell.execute_reply":"2021-12-23T16:37:09.573016Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#Initializing train and test data\nx_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\nprint('Train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:37:09.575357Z","iopub.execute_input":"2021-12-23T16:37:09.575768Z","iopub.status.idle":"2021-12-23T16:38:11.097839Z","shell.execute_reply.started":"2021-12-23T16:37:09.575717Z","shell.execute_reply":"2021-12-23T16:38:11.097042Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#Choosing 300 random samples from test data\ntest_samples = 300\ntest_files, test_targets = read_and_normalize_sampled_test_data(test_samples, img_rows, img_cols, color_type)\nprint('Test shape:', test_files.shape)\nprint(test_files.shape[0], 'Test samples')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:11.099342Z","iopub.execute_input":"2021-12-23T16:38:11.099894Z","iopub.status.idle":"2021-12-23T16:38:12.724781Z","shell.execute_reply.started":"2021-12-23T16:38:11.099823Z","shell.execute_reply":"2021-12-23T16:38:12.724003Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.countplot(x = 'classname', data = images_list)\nplt.ylabel('Count')\nplt.title('Classes')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:12.726249Z","iopub.execute_input":"2021-12-23T16:38:12.726755Z","iopub.status.idle":"2021-12-23T16:38:12.918253Z","shell.execute_reply.started":"2021-12-23T16:38:12.726704Z","shell.execute_reply":"2021-12-23T16:38:12.917531Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"activity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:12.921458Z","iopub.execute_input":"2021-12-23T16:38:12.921793Z","iopub.status.idle":"2021-12-23T16:38:12.927321Z","shell.execute_reply.started":"2021-12-23T16:38:12.921738Z","shell.execute_reply":"2021-12-23T16:38:12.926171Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:12.930839Z","iopub.execute_input":"2021-12-23T16:38:12.931447Z","iopub.status.idle":"2021-12-23T16:38:14.950696Z","shell.execute_reply.started":"2021-12-23T16:38:12.931392Z","shell.execute_reply":"2021-12-23T16:38:14.949833Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#Setting parameters for model training execution\nbatch_size = 40\nnb_epoch = 10\n\nmodels_dir = \"saved_models\"\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \ncheckpointer = ModelCheckpoint(filepath='saved_models/weights_best_vanilla.hdf5', \n                               monitor='val_loss', mode='min',\n                               verbose=1, save_best_only=True)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\ncallbacks = [checkpointer, es]","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:14.951927Z","iopub.execute_input":"2021-12-23T16:38:14.952311Z","iopub.status.idle":"2021-12-23T16:38:14.960044Z","shell.execute_reply.started":"2021-12-23T16:38:14.952270Z","shell.execute_reply":"2021-12-23T16:38:14.959278Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"<h2>Model Implementation</h2>","metadata":{}},{"cell_type":"markdown","source":"**Vanilla CNN with optimized networks**","metadata":{}},{"cell_type":"code","source":"def create_model():\n    # Optimised Vanilla CNN model\n    model = Sequential()\n\n    ## CNN 1\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 2\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n    \n    ## CNN 3\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n    \n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:14.961921Z","iopub.execute_input":"2021-12-23T16:38:14.962388Z","iopub.status.idle":"2021-12-23T16:38:14.982967Z","shell.execute_reply.started":"2021-12-23T16:38:14.962337Z","shell.execute_reply":"2021-12-23T16:38:14.982003Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model = create_model()\n\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:14.984350Z","iopub.execute_input":"2021-12-23T16:38:14.984964Z","iopub.status.idle":"2021-12-23T16:38:15.611017Z","shell.execute_reply.started":"2021-12-23T16:38:14.984574Z","shell.execute_reply":"2021-12-23T16:38:15.610189Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#Model 1 execution\nhistory_v1 = model.fit(x_train, y_train, \n          validation_data=(x_test, y_test),\n          callbacks=callbacks,\n          epochs=nb_epoch, batch_size=50, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:38:15.612280Z","iopub.execute_input":"2021-12-23T16:38:15.612722Z","iopub.status.idle":"2021-12-23T16:40:18.005847Z","shell.execute_reply.started":"2021-12-23T16:38:15.612670Z","shell.execute_reply":"2021-12-23T16:40:18.004955Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def plot_train_history(history):\n    # Summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:18.007117Z","iopub.execute_input":"2021-12-23T16:40:18.007401Z","iopub.status.idle":"2021-12-23T16:40:18.015709Z","shell.execute_reply.started":"2021-12-23T16:40:18.007354Z","shell.execute_reply":"2021-12-23T16:40:18.014851Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"plot_train_history(history_v1)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:18.017296Z","iopub.execute_input":"2021-12-23T16:40:18.017850Z","iopub.status.idle":"2021-12-23T16:40:18.297713Z","shell.execute_reply.started":"2021-12-23T16:40:18.017717Z","shell.execute_reply":"2021-12-23T16:40:18.296720Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=1)\nprint('Test Accuracy: ', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:18.299324Z","iopub.execute_input":"2021-12-23T16:40:18.299790Z","iopub.status.idle":"2021-12-23T16:40:19.559687Z","shell.execute_reply.started":"2021-12-23T16:40:18.299586Z","shell.execute_reply":"2021-12-23T16:40:19.558836Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"**Testing the model with test images**","metadata":{}},{"cell_type":"code","source":"def plot_test_class(model, test_files, image_number, color_type=1):\n    img_brute = test_files[image_number]\n    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_brute, cmap='gray')\n\n    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n\n    y_prediction = model.predict(new_img, batch_size=batch_size, verbose=1)\n    print('Y prediction: {}'.format(y_prediction))\n    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:19.560900Z","iopub.execute_input":"2021-12-23T16:40:19.561185Z","iopub.status.idle":"2021-12-23T16:40:19.568101Z","shell.execute_reply.started":"2021-12-23T16:40:19.561134Z","shell.execute_reply":"2021-12-23T16:40:19.567292Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"plot_test_class(model, test_files, 10)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:19.569438Z","iopub.execute_input":"2021-12-23T16:40:19.569877Z","iopub.status.idle":"2021-12-23T16:40:20.141592Z","shell.execute_reply.started":"2021-12-23T16:40:19.569817Z","shell.execute_reply":"2021-12-23T16:40:20.140827Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"plot_test_class(model, test_files, 251)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:20.142898Z","iopub.execute_input":"2021-12-23T16:40:20.143342Z","iopub.status.idle":"2021-12-23T16:40:20.306202Z","shell.execute_reply.started":"2021-12-23T16:40:20.143292Z","shell.execute_reply":"2021-12-23T16:40:20.305252Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"plot_test_class(model, test_files, 143) ","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:20.307908Z","iopub.execute_input":"2021-12-23T16:40:20.308519Z","iopub.status.idle":"2021-12-23T16:40:20.473949Z","shell.execute_reply.started":"2021-12-23T16:40:20.308463Z","shell.execute_reply":"2021-12-23T16:40:20.473101Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with Transfer Learning Approach**","metadata":{}},{"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:20.475488Z","iopub.execute_input":"2021-12-23T16:40:20.475824Z","iopub.status.idle":"2021-12-23T16:40:21.231257Z","shell.execute_reply.started":"2021-12-23T16:40:20.475768Z","shell.execute_reply":"2021-12-23T16:40:21.230286Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#training data and test data\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:21.233010Z","iopub.execute_input":"2021-12-23T16:40:21.233315Z","iopub.status.idle":"2021-12-23T16:40:21.240190Z","shell.execute_reply.started":"2021-12-23T16:40:21.233266Z","shell.execute_reply":"2021-12-23T16:40:21.239402Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"#Using transfer learning to train the CNN\ndef vgg_std16_model(img_rows, img_cols, color_type=3):\n    nb_classes = 10\n    # Remove fully connected layer and replace with softmax for classifying 10 classes\n    vgg16_model = VGG16(weights=\"imagenet\", include_top=False)\n\n    # Freeze all layers of the pre-trained model\n    for layer in vgg16_model.layers:\n        layer.trainable = False\n        \n    x = vgg16_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    predictions = Dense(nb_classes, activation = 'softmax')(x)\n\n    model = Model(input = vgg16_model.input, output = predictions)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:21.241692Z","iopub.execute_input":"2021-12-23T16:40:21.242253Z","iopub.status.idle":"2021-12-23T16:40:21.251182Z","shell.execute_reply.started":"2021-12-23T16:40:21.242203Z","shell.execute_reply":"2021-12-23T16:40:21.250441Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model_vgg16 = vgg_std16_model(img_rows, img_cols)\n\nmodel_vgg16.summary()\n\nmodel_vgg16.compile(loss='categorical_crossentropy',\n                         optimizer='rmsprop',\n                         metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:21.254048Z","iopub.execute_input":"2021-12-23T16:40:21.254531Z","iopub.status.idle":"2021-12-23T16:40:21.636182Z","shell.execute_reply.started":"2021-12-23T16:40:21.254477Z","shell.execute_reply":"2021-12-23T16:40:21.635401Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"training_generator = train_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train', \n                                                 target_size = (img_rows, img_cols), \n                                                 batch_size = batch_size,\n                                                 shuffle=True,\n                                                 class_mode='categorical', subset=\"training\")\n\nvalidation_generator = test_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train', \n                                                   target_size = (img_rows, img_cols), \n                                                   batch_size = batch_size,\n                                                   shuffle=False,\n                                                   class_mode='categorical', subset=\"validation\")\nnb_train_samples = 17943\nnb_validation_samples = 4481","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:21.637491Z","iopub.execute_input":"2021-12-23T16:40:21.637953Z","iopub.status.idle":"2021-12-23T16:40:26.392404Z","shell.execute_reply.started":"2021-12-23T16:40:21.637902Z","shell.execute_reply":"2021-12-23T16:40:26.391639Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"!rm -f saved_models/weights_best_vgg16.hdf5","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:40:26.394003Z","iopub.execute_input":"2021-12-23T16:40:26.394292Z","iopub.status.idle":"2021-12-23T16:40:27.152932Z","shell.execute_reply.started":"2021-12-23T16:40:26.394245Z","shell.execute_reply":"2021-12-23T16:40:27.151880Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#Model 2 execution\ncheckpoint = ModelCheckpoint('saved_models/weights_best_vgg16.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nhistory_v2 = model_vgg16.fit_generator(training_generator,\n                         steps_per_epoch = nb_train_samples // batch_size,\n                         epochs = 5, \n                         callbacks=[es, checkpoint],\n                         verbose = 1,\n                         class_weight='auto',\n                         validation_data = validation_generator,\n                         validation_steps = nb_validation_samples // batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:48:50.866980Z","iopub.execute_input":"2021-12-23T16:48:50.867344Z","iopub.status.idle":"2021-12-23T16:59:26.516971Z","shell.execute_reply.started":"2021-12-23T16:48:50.867287Z","shell.execute_reply":"2021-12-23T16:59:26.516074Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"model_vgg16.load_weights('saved_models/weights_best_vgg16.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:46:52.809977Z","iopub.execute_input":"2021-12-23T16:46:52.810284Z","iopub.status.idle":"2021-12-23T16:46:52.888166Z","shell.execute_reply.started":"2021-12-23T16:46:52.810230Z","shell.execute_reply":"2021-12-23T16:46:52.887275Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"plot_train_history(history_v2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:46:52.892737Z","iopub.execute_input":"2021-12-23T16:46:52.893685Z","iopub.status.idle":"2021-12-23T16:46:53.229048Z","shell.execute_reply.started":"2021-12-23T16:46:52.893071Z","shell.execute_reply":"2021-12-23T16:46:53.227927Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"**Testing the model with test images**","metadata":{}},{"cell_type":"code","source":"def plot_vgg16_test_class(model, test_files, image_number):\n    img_brute = test_files[image_number]\n\n    im = cv2.resize(cv2.cvtColor(img_brute, cv2.COLOR_BGR2RGB), (img_rows,img_cols)).astype(np.float32) / 255.0\n    im = np.expand_dims(im, axis =0)\n\n    img_display = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_display, cmap='gray')\n\n    y_preds = model.predict(im, batch_size=batch_size, verbose=1)\n    print(y_preds)\n    y_prediction = np.argmax(y_preds)\n    print('Y Prediction: {}'.format(y_prediction))\n    print('Predicted as: {}'.format(activity_map.get('c{}'.format(y_prediction))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:46:53.230913Z","iopub.execute_input":"2021-12-23T16:46:53.231398Z","iopub.status.idle":"2021-12-23T16:46:53.242254Z","shell.execute_reply.started":"2021-12-23T16:46:53.231187Z","shell.execute_reply":"2021-12-23T16:46:53.241103Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"plot_vgg16_test_class(model_vgg16, test_files, 133)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:46:53.244135Z","iopub.execute_input":"2021-12-23T16:46:53.244828Z","iopub.status.idle":"2021-12-23T16:46:53.527443Z","shell.execute_reply.started":"2021-12-23T16:46:53.244439Z","shell.execute_reply":"2021-12-23T16:46:53.525739Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"plot_vgg16_test_class(model_vgg16, test_files, 125)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:46:53.530930Z","iopub.execute_input":"2021-12-23T16:46:53.531219Z","iopub.status.idle":"2021-12-23T16:46:53.698568Z","shell.execute_reply.started":"2021-12-23T16:46:53.531163Z","shell.execute_reply":"2021-12-23T16:46:53.697789Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"plot_vgg16_test_class(model_vgg16, test_files, 208)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T16:46:53.700152Z","iopub.execute_input":"2021-12-23T16:46:53.700449Z","iopub.status.idle":"2021-12-23T16:46:53.865088Z","shell.execute_reply.started":"2021-12-23T16:46:53.700398Z","shell.execute_reply":"2021-12-23T16:46:53.864132Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"**Inferences:**<br>\n1) In the optmized CNN model, We observe that the model started overfitting which lead to the model to classify the test instances to wrong target classes.<br>\n2) As an optimization to the overfitting, A transfer learning approach was implemented to the CNN Model and trained on the same image set.<br>\n3) The test cases verfied in the trnasfer learning model gives accurate results and predicts the activities of the drivers.","metadata":{}}]}